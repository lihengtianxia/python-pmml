<?xml version='1.0' encoding='UTF-8'?>
<Header copyright="Copyright (c) 2018 NIST" description="ResNet50 Deep Neural Network Model">
  <DataDictionary numberOfFields="1">
    <DataField channels="3" dataType="image" height="300" name="I" width="300"/>
  </DataDictionary>
  <DeepNeuralNetwork modelname="Deep Neural Network" functionname="regression">
    <Layer name="input_2" type="InputLayer">
      <InputSize>
        <Array n="3" type="int">224 224 3</Array>
      </InputSize>
    </Layer>
    <Layer name="conv1_pad" type="ZeroPadding2D">
      <Padding>
        <Array n="4" type="int">3 3 3 3</Array>
      </Padding>
    </Layer>
    <Layer activation="linear" inbound_node="conv1_pad" name="conv1" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">7 7</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn_conv1"/>
    <Layer type="Activation" activation="relu" name="activation_1"/>
    <Layer name="pool1_pad" type="ZeroPadding2D">
      <Padding>
        <Array n="4" type="int">1 1 1 1</Array>
      </Padding>
    </Layer>
    <Layer name="max_pooling2d_1" type="MaxPooling2D">
      <PoolSize>
        <Array n="2" type="int">3 3</Array>
      </PoolSize>
      <Strides>
        <Array n="2" type="int">2 2</Array>
      </Strides>
    </Layer>
    <Layer activation="linear" inbound_node="max_pooling2d_1" name="res2a_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2a_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_2"/>
    <Layer activation="linear" inbound_node="activation_2" name="res2a_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2a_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_3"/>
    <Layer activation="linear" inbound_node="activation_3" name="res2a_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer activation="linear" inbound_node="max_pooling2d_1" name="res2a_branch1" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2a_branch2c"/>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2a_branch1"/>
    <Layer type="Merge" name="add_1" operator="add">
      <Inputs>
        <Array n="2" type="string">bn2a_branch2c bn2a_branch1</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_4"/>
    <Layer activation="linear" inbound_node="activation_4" name="res2b_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2b_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_5"/>
    <Layer activation="linear" inbound_node="activation_5" name="res2b_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2b_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_6"/>
    <Layer activation="linear" inbound_node="activation_6" name="res2b_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2b_branch2c"/>
    <Layer type="Merge" name="add_2" operator="add">
      <Inputs>
        <Array n="2" type="string">bn2b_branch2c activation_4</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_7"/>
    <Layer activation="linear" inbound_node="activation_7" name="res2c_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2c_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_8"/>
    <Layer activation="linear" inbound_node="activation_8" name="res2c_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="64">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2c_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_9"/>
    <Layer activation="linear" inbound_node="activation_9" name="res2c_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn2c_branch2c"/>
    <Layer type="Merge" name="add_3" operator="add">
      <Inputs>
        <Array n="2" type="string">bn2c_branch2c activation_7</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_10"/>
    <Layer activation="linear" inbound_node="activation_10" name="res3a_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3a_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_11"/>
    <Layer activation="linear" inbound_node="activation_11" name="res3a_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3a_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_12"/>
    <Layer activation="linear" inbound_node="activation_12" name="res3a_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer activation="linear" inbound_node="activation_10" name="res3a_branch1" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3a_branch2c"/>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3a_branch1"/>
    <Layer type="Merge" name="add_4" operator="add">
      <Inputs>
        <Array n="2" type="string">bn3a_branch2c bn3a_branch1</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_13"/>
    <Layer activation="linear" inbound_node="activation_13" name="res3b_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3b_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_14"/>
    <Layer activation="linear" inbound_node="activation_14" name="res3b_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3b_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_15"/>
    <Layer activation="linear" inbound_node="activation_15" name="res3b_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3b_branch2c"/>
    <Layer type="Merge" name="add_5" operator="add">
      <Inputs>
        <Array n="2" type="string">bn3b_branch2c activation_13</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_16"/>
    <Layer activation="linear" inbound_node="activation_16" name="res3c_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3c_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_17"/>
    <Layer activation="linear" inbound_node="activation_17" name="res3c_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3c_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_18"/>
    <Layer activation="linear" inbound_node="activation_18" name="res3c_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3c_branch2c"/>
    <Layer type="Merge" name="add_6" operator="add">
      <Inputs>
        <Array n="2" type="string">bn3c_branch2c activation_16</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_19"/>
    <Layer activation="linear" inbound_node="activation_19" name="res3d_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3d_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_20"/>
    <Layer activation="linear" inbound_node="activation_20" name="res3d_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="128">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3d_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_21"/>
    <Layer activation="linear" inbound_node="activation_21" name="res3d_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn3d_branch2c"/>
    <Layer type="Merge" name="add_7" operator="add">
      <Inputs>
        <Array n="2" type="string">bn3d_branch2c activation_19</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_22"/>
    <Layer activation="linear" inbound_node="activation_22" name="res4a_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4a_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_23"/>
    <Layer activation="linear" inbound_node="activation_23" name="res4a_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4a_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_24"/>
    <Layer activation="linear" inbound_node="activation_24" name="res4a_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer activation="linear" inbound_node="activation_22" name="res4a_branch1" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4a_branch2c"/>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4a_branch1"/>
    <Layer type="Merge" name="add_8" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4a_branch2c bn4a_branch1</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_25"/>
    <Layer activation="linear" inbound_node="activation_25" name="res4b_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4b_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_26"/>
    <Layer activation="linear" inbound_node="activation_26" name="res4b_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4b_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_27"/>
    <Layer activation="linear" inbound_node="activation_27" name="res4b_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4b_branch2c"/>
    <Layer type="Merge" name="add_9" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4b_branch2c activation_25</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_28"/>
    <Layer activation="linear" inbound_node="activation_28" name="res4c_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4c_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_29"/>
    <Layer activation="linear" inbound_node="activation_29" name="res4c_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4c_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_30"/>
    <Layer activation="linear" inbound_node="activation_30" name="res4c_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4c_branch2c"/>
    <Layer type="Merge" name="add_10" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4c_branch2c activation_28</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_31"/>
    <Layer activation="linear" inbound_node="activation_31" name="res4d_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4d_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_32"/>
    <Layer activation="linear" inbound_node="activation_32" name="res4d_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4d_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_33"/>
    <Layer activation="linear" inbound_node="activation_33" name="res4d_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4d_branch2c"/>
    <Layer type="Merge" name="add_11" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4d_branch2c activation_31</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_34"/>
    <Layer activation="linear" inbound_node="activation_34" name="res4e_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4e_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_35"/>
    <Layer activation="linear" inbound_node="activation_35" name="res4e_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4e_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_36"/>
    <Layer activation="linear" inbound_node="activation_36" name="res4e_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4e_branch2c"/>
    <Layer type="Merge" name="add_12" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4e_branch2c activation_34</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_37"/>
    <Layer activation="linear" inbound_node="activation_37" name="res4f_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4f_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_38"/>
    <Layer activation="linear" inbound_node="activation_38" name="res4f_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="256">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4f_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_39"/>
    <Layer activation="linear" inbound_node="activation_39" name="res4f_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="1024">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn4f_branch2c"/>
    <Layer type="Merge" name="add_13" operator="add">
      <Inputs>
        <Array n="2" type="string">bn4f_branch2c activation_37</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_40"/>
    <Layer activation="linear" inbound_node="activation_40" name="res5a_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5a_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_41"/>
    <Layer activation="linear" inbound_node="activation_41" name="res5a_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5a_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_42"/>
    <Layer activation="linear" inbound_node="activation_42" name="res5a_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="2048">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer activation="linear" inbound_node="activation_40" name="res5a_branch1" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="2048">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">2 2</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5a_branch2c"/>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5a_branch1"/>
    <Layer type="Merge" name="add_14" operator="add">
      <Inputs>
        <Array n="2" type="string">bn5a_branch2c bn5a_branch1</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_43"/>
    <Layer activation="linear" inbound_node="activation_43" name="res5b_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5b_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_44"/>
    <Layer activation="linear" inbound_node="activation_44" name="res5b_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5b_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_45"/>
    <Layer activation="linear" inbound_node="activation_45" name="res5b_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="2048">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5b_branch2c"/>
    <Layer type="Merge" name="add_15" operator="add">
      <Inputs>
        <Array n="2" type="string">bn5b_branch2c activation_43</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_46"/>
    <Layer activation="linear" inbound_node="activation_46" name="res5c_branch2a" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5c_branch2a"/>
    <Layer type="Activation" activation="relu" name="activation_47"/>
    <Layer activation="linear" inbound_node="activation_47" name="res5c_branch2b" padding="same" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="512">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">3 3</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5c_branch2b"/>
    <Layer type="Activation" activation="relu" name="activation_48"/>
    <Layer activation="linear" inbound_node="activation_48" name="res5c_branch2c" padding="valid" type="Conv2D" use_bias="True">
      <ConvolutionalKernel channels="2048">
        <DilationRate>
          <Array n="2" type="int">1 1</Array>
        </DilationRate>
        <KernelSize>
          <Array n="2" type="int">1 1</Array>
        </KernelSize>
        <KernelStride>
          <Array n="2" type="int">1 1</Array>
        </KernelStride>
      </ConvolutionalKernel>
    </Layer>
    <Layer type="BatchNormalization" axis="3" center="True" momentum="0.99" name="bn5c_branch2c"/>
    <Layer type="Merge" name="add_16" operator="add">
      <Inputs>
        <Array n="2" type="string">bn5c_branch2c activation_46</Array>
      </Inputs>
    </Layer>
    <Layer type="Activation" activation="relu" name="activation_49"/>
    <Layer name="avg_pool" type="GlobalAveragePooling2D"/>
    <Layer activation="softmax" channels="1000" name="fc1000" type="Dense"/>
    <Weights encoding="hdf5" href="weights.h5"/>
  </DeepNeuralNetwork>
</Header>
